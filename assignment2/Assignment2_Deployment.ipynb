{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPAp+2Q/3iShXh4ZlVgsW/N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":20,"metadata":{"id":"4YcPtu9PGGFO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683488458124,"user_tz":-120,"elapsed":3772,"user":{"displayName":"Rubing Wang","userId":"08566197663081581441"}},"outputId":"d4fd5773-0209-4705-9bdd-439115a3725a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/Assignment2\n"]}],"source":["# mount my google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# change working directory \n","%cd /content/drive/My Drive/Assignment2"]},{"cell_type":"code","source":["# install deployment packages\n","!pip install flask\n","!pip install keras\n","!pip intall PIL"],"metadata":{"id":"TVmWrb0vGMxR","executionInfo":{"status":"ok","timestamp":1683488474678,"user_tz":-120,"elapsed":10060,"user":{"displayName":"Rubing Wang","userId":"08566197663081581441"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Code for depolyment in Local PC \n","from flask import Flask, request, jsonify\n","import keras\n","import numpy as np\n","from PIL import Image\n","\n","# Load the pre-trained model\n","model = keras.models.load_model('cuisine_model.h5')\n","\n","# Create a Flask application\n","app = Flask(__name__)\n","\n","# Define a route that accepts POST requests with uploaded image files and returns the prediction\n","@app.route('/predict', methods=['POST'])\n","def predict():\n","    # Get the uploaded file\n","    file = request.files['file']\n","    # Convert the file to a PIL Image object\n","    img = Image.open(file.stream)\n","    # Resize the image to the size required by the model\n","    img = img.resize((224, 224))\n","    # Convert the image to a numpy array\n","    img_arr = np.array(img)\n","    # Convert the image from RGB format to BGR format (consistent with the pre-trained model)\n","    img_arr = img_arr[:, :, ::-1]\n","    # Scale the values of the image to be between 0 and 1 (consistent with the preprocessing of the pre-trained model)\n","    img_arr = img_arr.astype('float32') / 255.0\n","    # Add an extra dimension to the image to match the input shape of the model\n","    img_arr = np.expand_dims(img_arr, axis=0)\n","    # Use the pre-trained model for prediction\n","    pred = model.predict(img_arr)[0]\n","    # Create a dictionary to hold the prediction result\n","    result = {'Japanese': pred[0], 'Italian': pred[1], 'Chinese': pred[2], 'French': pred[3]}\n","    # If the maximum probability is less than 0.5, classify as \"Other\"\n","    if max(pred) < 0.5:\n","        result['Other'] = 1.0\n","    else:\n","        # Convert the prediction result to a dictionary and return it\n","        result = {'Japanese': pred[0], 'Italian': pred[1], 'Chinese': pred[2], 'French': pred[3]}\n","    return jsonify(result)\n","\n","# Run the application\n","if __name__ == '__main__':\n","    app.run(host='0.0.0.0', port=5000, debug=True)\n","    "],"metadata":{"id":"SLRlBgtEGQju","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683489096905,"user_tz":-120,"elapsed":163639,"user":{"displayName":"Rubing Wang","userId":"08566197663081581441"}},"outputId":"fa11b17a-8131-49a1-db13-23c5644db14b"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":[" * Serving Flask app '__main__'\n"," * Debug mode: on\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on all addresses (0.0.0.0)\n"," * Running on http://127.0.0.1:5000\n"," * Running on http://172.28.0.12:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n","INFO:werkzeug: * Restarting with stat\n"]}]},{"cell_type":"code","source":["# Install additional packages only deploy model in Colab Notbook\n","!pip install flask-ngrok\n","!pip install pyngrok"],"metadata":{"id":"OKiUJiqQx9Lp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code for deployment in Colab by third website server\n","from flask_ngrok import run_with_ngrok\n","from flask import Flask, request, jsonify\n","import keras\n","import numpy as np\n","from PIL import Image\n","\n","# Load the pre-trained model\n","model = keras.models.load_model('cuisine_model.h5')\n","\n","# Create a Flask application\n","app = Flask(__name__)\n","\n","# Set up ngrok and give authtoken (here is for ngrok account Rubing Wang)\n","from pyngrok import ngrok\n","ngrok.set_auth_token('2PTUDFWN0ZX1gvit7ALvL14qq4y_5p8ddyGn85qRXNvGq85a7')\n","#public_url = ngrok.connect(port=5000).public_url\n","public_url = ngrok.connect(addr=\"127.0.0.1:5000\")\n","print(' * ngrok tunnel:', public_url)\n","\n","\n","# Define a route that accepts POST requests with uploaded image files and returns the prediction\n","@app.route('/predict', methods=['POST'])\n","def predict():\n","    # Get the uploaded file\n","    file = request.files['file']\n","    # Convert the file to a PIL Image object\n","    img = Image.open(file.stream)\n","    # Resize the image to the size required by the model\n","    img = img.resize((224, 224))\n","    # Convert the image to a numpy array\n","    img_arr = np.array(img)\n","    # Convert the image from RGB format to BGR format (consistent with the pre-trained model)\n","    img_arr = img_arr[:, :, ::-1]\n","    # Scale the values of the image to be between 0 and 1 (consistent with the preprocessing of the pre-trained model)\n","    img_arr = img_arr.astype('float32') / 255.0\n","    # Add an extra dimension to the image to match the input shape of the model\n","    img_arr = np.expand_dims(img_arr, axis=0)\n","    # Use the pre-trained model for prediction\n","    pred = model.predict(img_arr)[0]\n","    # Create a dictionary to hold the prediction result\n","    result = {'Japanese': pred[0], 'Italian': pred[1], 'Chinese': pred[2], 'French': pred[3]}\n","    # If the maximum probability is less than 0.5, classify as \"Other\"\n","    if max(pred) < 0.5:\n","        result['Other'] = 1.0\n","    else:\n","        # Convert the prediction result to a dictionary and return it\n","        result = {'Japanese': pred[0], 'Italian': pred[1], 'Chinese': pred[2], 'French': pred[3]}\n","    return jsonify(result)\n","\n","\n","# Run the application\n","if __name__ == '__main__':\n","    # Run the Flask application with ngrok\n","    run_with_ngrok(app)\n","    app.run()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sbF7FAWESONh","executionInfo":{"status":"ok","timestamp":1683489224040,"user_tz":-120,"elapsed":989,"user":{"displayName":"Rubing Wang","userId":"08566197663081581441"}},"outputId":"21570b02-7ae3-4ec9-a750-634ac6136215"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:pyngrok.process.ngrok:t=2023-05-07T19:53:43+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"]},{"output_type":"stream","name":"stdout","text":[" * ngrok tunnel: NgrokTunnel: \"https://afee-34-83-73-92.ngrok-free.app\" -> \"http://127.0.0.1:5000\"\n"," * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"]}]}]}